{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "steady-spice",
   "metadata": {},
   "outputs": [],
   "source": [
    "import satimagets as sits\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import gdal\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seasonal-ordinance",
   "metadata": {},
   "outputs": [],
   "source": [
    "S2_PATH = \"Y:\\\\Harmonisation_PS_S2\\\\m3sat_s2output\\\\\"#\"D:\\\\M3sat_S2output\\\\\"\n",
    "PS_PATH = \"Y:\\PS\\Mosaic\\PS_5m\\\\\"\n",
    "PS_OLD = \"Y:\\\\Harmonisation_PS_S2\\\\output_S2_spatial\\\\\"\n",
    "PS_PATHre = \"Y:\\\\\\\\Harmonisation_PS_S2\\\\\\\\m3sat_s2output\\\\\\\\\"\n",
    "PS_OLDre = \"Y:\\\\\\\\Harmonisation_PS_S2\\\\\\\\output_S2_spatial\\\\\\\\\"\n",
    "locations = [\"Izola\", \"Radenci\", \"Jesenice\", \"Kranj\"]\n",
    "DF_PATH = \"C:\\\\Users\\\\mracic\\\\Univerza v Ljubljani\\\\Fetai, Bujar - satimagets-master\\\\\"\n",
    "dfs = pd.read_excel(DF_PATH+\"Harmonisation_PS_S2.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incomplete-locator",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix the path to S2 file\n",
    "dfs[\"S2_path\"] = dfs[\"S2_path\"].apply(lambda x: re.sub(PS_OLDre,PS_PATHre,x))\n",
    "# Add paths to masks\n",
    "dfs[\"S2_mask_path\"] = dfs[\"S2_path\"].apply(lambda x: re.sub(\"m_S2\",\"m_mask_S2\",x))\n",
    "dfs[\"PS_udm_path\"] = dfs[\"PS_Path\"].apply(lambda x: re.sub(\"analytic\",\"udm\",x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "relevant-penalty",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_im(im_file):\n",
    "    try:\n",
    "        return gdal.Open(im_file)\n",
    "    except:\n",
    "        print('Could not open:', im_file)\n",
    "        sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "integral-property",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "usable_thres = 0.3\n",
    "coeff_df = pd.DataFrame(columns=[\"PS_filename\", \"PS_Date\", \"S2_filename\", \"S2_Date\", \"band\", \"perc_valid\", \"m\", \"b\"])\n",
    "skip_list = [\"I5_20181004_101f_analytic_mosaic.tif\", \"K5_20190506\"] # K5_20190506_1040_udm_mosaic.tif \n",
    "skip = False \n",
    "for loc_name in locations:\n",
    "    print(loc_name)\n",
    "    sub_dfs = dfs[dfs[\"Location\"]==loc_name]\n",
    "    file_1_src = open_im(sub_dfs.iloc[0][\"PS_Path\"])\n",
    "    file_2_src = open_im(sub_dfs.iloc[0][\"S2_path\"])\n",
    "    # Find overlap\n",
    "    im_bb, im_res, im_srs = sits.image_raster_overlap(file_1_src, file_2_src, 0)\n",
    "    # Set resolution\n",
    "    im_res = 100\n",
    "    for index, row in sub_dfs.iterrows():\n",
    "        skip = False\n",
    "        file_1 = row[\"PS_Path\"]\n",
    "        file_1_mask = row[\"PS_udm_path\"]\n",
    "        file_2 = row[\"S2_path\"]\n",
    "        file_2_mask = row[\"S2_mask_path\"]\n",
    "        # check if file is on the skip list\n",
    "        for x in skip_list:\n",
    "            if x in file_1:\n",
    "                skip = True\n",
    "        # do the skip\n",
    "        if skip:\n",
    "            continue\n",
    "        # Load images and masks\n",
    "        file_1_src = open_im(file_1)\n",
    "        file_2_src = open_im(file_2)\n",
    "        file_1_mask = open_im(file_1_mask)\n",
    "        file_2_mask = open_im(file_2_mask)\n",
    "        # Resample images and masks\n",
    "        im_1 = sits.image_raster_resample(file_1_src, im_bb, im_res, im_srs, 0)\n",
    "        im_2 = sits.image_raster_resample(file_2_src, im_bb, im_res, im_srs, 0)\n",
    "        im_1_m = sits.image_raster_resample(file_1_mask, im_bb, im_res, im_srs)\n",
    "        im_2_m = sits.image_raster_resample(file_2_mask, im_bb, im_res, im_srs)\n",
    "        # Merge masks\n",
    "        mask = sits.mask_data(im_2_m, im_1_m, 0)\n",
    "        mask = sits.mask_data(mask, im_2_m, 100)        \n",
    "        # Mask images\n",
    "        im_1 = sits.mask_data(im_1, mask, 100)\n",
    "        im_2 = sits.mask_data(im_2, mask, 100)        \n",
    "        # Add NDVI\n",
    "        \n",
    "        # Skip image if it is too cloudy or has only one value\n",
    "        perc_valid = np.sum(~np.isnan(mask))/mask.size\n",
    "        if perc_valid < usable_thres or len(np.unique(im_1[:,~np.isnan(mask)])) < 2:\n",
    "            continue\n",
    "\n",
    "        if im_1.shape[0] < 1:\n",
    "            sits.image_scatterplot(im_1[[1,2,3],:,:]/10000, im_2[[1, 2, 3],:,:], im1_in_name=\"Planet\", im2_in_name=\"Sentinel\", sample=10000)\n",
    "        for band in range(im_1.shape[0]):\n",
    "            m, b = np.polyfit(im_1[band][~np.isnan(mask)], im_2[band][~np.isnan(mask)], 1)\n",
    "            coeff_df.loc[len(coeff_df.index)] = np.append(row[[\"PS_filename\", \"PS_Date\", \"S2_filename\", \"S2_Date\"]].values,[band, perc_valid, m, b])\n",
    "        \n",
    "        \n",
    "        # Visualize correlation per band\n",
    "        #sits.image_scatterplot(im_1[[1,2,3],:,:]/10000, im_2[[1, 2, 3],:,:], im1_in_name=\"Planet\", im2_in_name=\"Sentinel\", sample=10000)\n",
    "        \n",
    "    coeff_df.to_csv(\"csv/\"+loc_name+\"_coeff.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
